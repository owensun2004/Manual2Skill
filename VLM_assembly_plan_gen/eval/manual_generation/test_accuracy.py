import ast
import copy
from permutations import print_trees
from manual_generation.models import Model, SinglePartModel, SimilarityModel
from utils.meters import Meters
from manual_generation.eval import eval_assembly_tree
from tqdm import tqdm
from pprint import pprint
import argparse
from manual_generation.dataset import Dataset
from utils.data import build_tree_from_list, tree_to_list
import json
from pathlib import Path
import os
import sys
# sys.setrecursionlimit(30) 

PROJECT_ROOT = Path(__file__).parent.parent.parent.absolute()
OUTPUT_DIR = os.path.join(PROJECT_ROOT, "outputs")


def evaluate(model: Model, dataset: Dataset, check_symm: bool, args: argparse.Namespace):
    meters = Meters()
    count = 0
    improved_count = 0
    totally_correct_trees = 0

    # smallest furniture has 2 parts, largest has 16 parts
    if args.difficulty == 'easy':
        lower_bound = 2
        upper_bound = 4
    elif args.difficulty == 'medium':
        lower_bound = 5
        upper_bound = 6
    elif args.difficulty == 'hard':
        lower_bound = 7
        upper_bound = 8
    elif args.difficulty == 'impossible':
        lower_bound = 9
        upper_bound = 19
    else:
        lower_bound = 2
        upper_bound = 19

    if args.tree_dir == "ours":
        trees_dir = OUTPUT_DIR + "/default_gpt4o"
    else:
        trees_dir = OUTPUT_DIR + args.tree_dir

    for f in tqdm(dataset):
        found_iter = False
        if f['part_ct']>=lower_bound and f['part_ct']<=upper_bound:
            count += 1
            tree_gt = f['tree']
            if args.debug:
                print("==========================")
                print(f"Predicting assembly tree for: {f['category']}/{f['name']}")
            if check_symm:
                with open(f"{trees_dir}/{f['category']}/{f['name']}/tree.json", "r") as file:
                    tree_str = json.load(file)
                tree_list = json.loads(tree_str)
                tree_pred = build_tree_from_list(tree_list)
            # use baselines
            if not check_symm:
                tree_pred = model(f)
                tree_list = tree_to_list(tree_pred)
                # print(tree_list)
            tree_gt_list = tree_to_list(tree_gt)
            if are_nested_lists_equal(tree_list, tree_gt_list):
                totally_correct_trees += 1
                if args.debug:
                    print(f"NORMAL Predicted: {tree_list}, GT: {tree_gt_list}")
                found_iter = True
            else:
                if f['part_ct']>=9:
                    if args.debug:
                        print(f"NO TREES FOUND: Predicted: {tree_list}, GT: {tree_gt_list}")
                    continue
                with open(f"{PROJECT_ROOT}/data/preassembly_scenes/{f['category']}/{f['name']}/equiv_parts.txt", "r") as text_file:
                    data = text_file.read()
                nested_list = ast.literal_eval(data)
                tree_store = []
                print_trees(copy.deepcopy(tree_list), nested_list, tree_store)
                for indiv_tree in tree_store:
                    if f['part_ct']>=9:
                        break
                    if are_nested_lists_equal(indiv_tree, tree_gt_list):
                        totally_correct_trees += 1
                        improved_count += 1
                        if args.debug:
                            print(f"IMPROVED Predicted: {indiv_tree}, GT: {tree_gt_list}")
                        found_iter = True
                        break
                if not found_iter:
                    if args.debug:
                        print(f"NO TREES FOUND: Predicted: {indiv_tree}, GT: {tree_gt_list}")

    print("\n")
    if args.tree_dir == "ours":
        print("Results of assembly graphs generated by the authors' original experiments (same as the paper's Table I 'Ours' row)")
    elif args.tree_dir == "singlestep" and isinstance(model, SinglePartModel):
        print("Results of assembly graphs generated by the SingleStep baseline (same as the paper's Table I 'SingleStep' row)")
    elif args.tree_dir == "geocluster" and isinstance(model, SimilarityModel):
        print("Results of assembly graphs generated by the GeoCluster baseline (same as the paper's Table I 'Geocluster' row)")
    else:
        print("Results of assembly graphs generated by your inference at time: ", args.tree_dir)
    print("=======================================================================================================================")
    print(f"Number of furniture items with {lower_bound} - {upper_bound} parts: {count}")
    print(f"Number of furniture items with correct predicted assembly graphs: {totally_correct_trees}")
    print(f"Success rate: {totally_correct_trees}/{count} = {totally_correct_trees/count:.1%}")
    print("=======================================================================================================================\n")
    return meters

def find_max_val(dict):
    # Find largest value in result_tmp dictionary
    largest_value = float('-inf')
    for key, subdict in dict.items():
        if key != "no_children":
            for metric, value in subdict.items():
                # Update the largest value if the current value is greater
                if value > largest_value:
                    largest_value = value
    return largest_value


def are_nested_lists_equal(list1, list2):
    # Create deep copies of the lists to avoid modifying the originals
    list1_copy = copy.deepcopy(list1)
    list2_copy = copy.deepcopy(list2)
    
    # If both are not lists, compare directly
    if not isinstance(list1_copy, list) or not isinstance(list2_copy, list):
        return list1_copy == list2_copy
    
    # If lengths are different, they can't be equal
    if len(list1_copy) != len(list2_copy):
        return False
    
    # Recursively check each element in the lists
    for item1 in list1_copy:
        found_match = False
        for item2 in list2_copy:
            if are_nested_lists_equal(item1, item2):
                found_match = True
                list2_copy.remove(item2)  # Remove the matched item to avoid re-matching
                break
        if not found_match:
            return False
    
    return True


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--part_features_pkl', type=str)
    parser.add_argument('--data_json', type=str)
    parser.add_argument('--parts_dir', type=str)
    parser.add_argument('--tree_dir', type=str, default="ours")
    parser.add_argument('--difficulty', type=str, default='all')
    parser.add_argument("--debug",  type=bool, default=False)
    args = parser.parse_args()

    dataset = Dataset(data_json=args.data_json, parts_dir=args.parts_dir, part_features_pkl=args.part_features_pkl)
    evaluate_models = ['single_part', 'similarity']
    # evaluate_models = ['single_part']
    # evaluate_models = ['similarity']
    if 'single_part' in evaluate_models:
        single_part_model = SinglePartModel()
        similarity_model = SimilarityModel()
        check = True
        if args.tree_dir == "singlestep":
            check = False
            meters_single = evaluate(single_part_model, dataset, check, args)
        elif args.tree_dir == "geocluster":
            check = False
            meters = evaluate(similarity_model, dataset, check, args)
        else:
            meters_single = evaluate(single_part_model, dataset, check, args)
        # for k, v in meters.avg_dict().items():
        #     print(k, end=' ')

    # if 'similarity' in evaluate_models:
    #     similarity_model = SimilarityModel()
    #     meters = evaluate(similarity_model, dataset, check)
    #     pprint('Similarity Model:')
    #     pprint(meters.avg_dict())
    #     # for k, v in meters.avg_dict().items():
    #     #     print(k, end=' ')
    # pprint('Single Part Model:')
    # pprint(meters_single.avg_dict())
